#!/bin/bash
#
# Description:   Summit XL simulation on docker
#                bring-up script functions
#
# Company:       Robotnik Automation S.L.L.
# Creation Year: 2021
# Author:        Guillem Gari  <ggari@robotnik.es>

# FUNCTIONS
###########

function print_error() {
    local message="${1}"
    eval "echo -e "'"'"${err_colour}ERROR]${no_colour}:   ${message}"'"'" 2>&1"
}

function print_info() {
    local message="${1}"
    eval "echo -e "'"'"${nfo_colour}[INFO]${no_colour}:    ${message}"'"'""
}

function print_success() {
    local message="${1}"
    eval "echo -e "'"'"${suc_colour}[SUCCESS]${no_colour}: ${message}"'"'""
}

function set_path() {
    host_source_path="$(dirname "$(readlink -f "${0}")")"
    build_path="${host_source_path}"
    return 0
}

function tool_check() {
    local binary="${1}"
    if [[ -z "${binary}" ]];then
        return 1
    fi
    eval "${tool_check_cmd}"
    return $?
}

function tools_check() {
    local tools=("${@}")
    print_info "${nfo_str_tool_checking}"
    for tool in "${tools[@]}"; do
        if ! tool_check "${tool}"; then
            print_error "${err_str_required_tool_not_found}"
            return 1
        fi
    done
    print_success "${suc_str_tool_check_success}"
    return 0
}

function check_if_there_is_display() {
    print_info "${nfo_str_display}"
    if ! [[ -n $XDG_CURRENT_DESKTOP ]]; then
        print_error "${err_str_display}"
        return 1
    fi
    print_success "${suc_str_display}"
    return 0
}

function get_nvidia_cuda() {
    print_info "${nfo_str_cuda}"
    cuda_version="$(nvidia-smi -q | grep "CUDA Version" | sed 's/.*: //')"
    if ! [[ $cuda_version =~ ^[0-9]+(.[0-9]+)?$ ]]; then
        print_error "${err_str_cuda}"
        return 1
    fi
    print_success "${suc_str_cuda}"
    return 0
}

function find_nvidia_docker_local_image() {
    find_nvidia_docker_local_image_cmd="\
        docker image ls -q --filter=reference="${nvidia_repo}:${cuda_version}*base" | \
        grep -q -E '^[0-9a-f]*$' \
    "
    if ! eval "${find_nvidia_docker_local_image_cmd}"; then
        return 1
    fi

    nvidia_docker_image="$(\
        docker image ls --filter=reference="${nvidia_repo}:${cuda_version}*base" --format "{{.Repository}}:{{.Tag}}"
    )"
    if [[ -z "${nvidia_docker_image}" ]]; then
        return 1
    fi
    return 0
}

function find_nvidia_docker_remote_image() {
    nvidia_docker_image_tag="$(\
    wget -q "${nvidia_repo_full}" -O -  | \
    sed -e 's/[][]//g' -e 's/"//g' -e 's/ //g' | \
    tr '}' '\n'  | \
    awk -F: '{print $3}' | \
    grep ${cuda_version}.*base$ | \
    tail -n1 \
    )"
    if [[ -z "${nvidia_docker_image_tag}" ]]; then
        return 1
    fi
    nvidia_docker_image="${nvidia_repo}:${nvidia_docker_image_tag}"
    return 0
}

function find_nvidia_docker_image() {
    if find_nvidia_docker_local_image; then
        return 0
    fi
    if find_nvidia_docker_remote_image; then
        return 0
    fi
    return 1
}

function test_nvidia_docker() {
    if ! find_nvidia_docker_image; then
        print_error "${err_str_nvidia_docker_img_not_found}"
        return 1
    fi
    print_info "${nfo_str_nvidia_docker}"
    if ! docker run --rm --gpus all "${nvidia_docker_image}" nvidia-smi; then
        print_error "${err_str_nvidia_docker}"
        return 1
    fi
    print_success "${suc_str_nvidia_docker}"
    return 0
}

function build_image() {
    eval "image_complete_name=${image_complete_name}"
    print_info "${nfo_str_tool_building}"
    if ! docker build -f Dockerfile -t "${image_complete_name}" ..; then
        print_error "${suc_str_image_build}"
        return 1
    fi
    print_success "${suc_str_image_build}"
    return 0
}

function check_docker_instance_already_running() {
    print_info "${nfo_str_check_already_running}"
    if ! docker container ls -a | sed '1d' | awk '{print $2}' | grep -q ^${instance_name}$; then
        return 1
    fi
    print_success "${suc_str_already_running}"
    return 0
}

function delete_running_docker_instance() {
    print_info "${nfo_str_already_running}"
    if ! docker container rm --force "${instance_name}"; then
        print_error "${err_str_destroy_running_sim}"
        return 1
    fi
    print_success "${suc_str_destroy_running_sim}"
    return 0
}

function allow_screen() {
    if ! xhost + local:root &>/dev/null; then
        print_error "${err_str_x11_enable_server_access}"
        return 1
    fi
    return 0
}

function disable_screen() {
    if ! xhost - local:root &>/dev/null; then
        print_error "${err_str_x11_disable_server_access}"
        return 1
    fi
    return 0
}

function select_simulation() {
    if ! [[ -n "${ros_bringup_package_array[${selected_robot}]}" ]]; then
        print_error "${err_str_unrecognized_robot}"
        return 1
    fi
    ros_bringup_package="${ros_bringup_package_array[${selected_robot}]}"
    ros_launch_file="${ros_launch_file_array[${selected_robot}]}"

    if [[ -n "${selected_launch_file}" ]]; then
        ros_launch_file="${selected_launch_file}"
    fi

    if [[ -n "${selected_package}" ]]; then
        ros_bringup_package="${selected_package}"
    fi

    return 0
}

function run_simulation() {
    print_info "${nfo_str_running_simulation}"
    docker run --gpus all --rm \
        --env="DISPLAY=$DISPLAY" \
        --env="QT_X11_NO_MITSHM=1" \
        --device=/dev/dri \
        --group-add video \
        --device=/dev/snd:/dev/snd \
        --group-add audio \
        --net=host \
        --privileged \
        --volume="/tmp/.X11-unix:/tmp/.X11-unix:rw" \
        --env ROS_MASTER_URI="${ros_master_uri}" \
        --env GAZEBO_MASTER_URI="${gazebo_master_uri}" \
        --env ROS_BU_PKG="${ros_bringup_package}" \
        --env ROS_BU_LAUNCH="${ros_launch_file}" \
        --env NVIDIA_VISIBLE_DEVICES=0 \
        --name "${instance_name}" \
        "${image_complete_name}"
    return $?
}
